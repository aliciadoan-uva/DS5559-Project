{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Admission Prediction from NHAMCS\n",
    "## Progress report: Inital model evaluation\n",
    "### DS5559: Big Data Analysis\n",
    "### Thomas Hartka(trh6u), Alicia Doan(ad2ew), Michael Langmayr(ml8vp)\n",
    "Created: 8/2/2020\n",
    "  \n",
    "This script performs logistic regression to predict hospital admissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data directory\n",
    "data_dir = \"../data\"\n",
    "results_dir = \"../results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 314"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.feature import *  \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHAMCS = spark.read.parquet(data_dir + \"/NHAMCS_processed_bc.2014-2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform string indexing to prepare for OHE for residence variable\n",
    "rsi = StringIndexer(inputCol=\"RESIDNCE\", outputCol=\"RESINDEX\")\n",
    "simodel = rsi.fit(NHAMCS)\n",
    "NHAMCS = simodel.transform(NHAMCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform OHE on residence variable\n",
    "rohe = OneHotEncoder(inputCol='RESINDEX', outputCol='RESONE')\n",
    "NHAMCS = rohe.transform(NHAMCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble vector\n",
    "va = VectorAssembler(inputCols=[\"AGEYEAR\",\"RESONE\",'SEXMALE','ARRTIMEMIN','YEAR','PULSE','TEMPF', \\\n",
    "                                'RESPR','BPSYS','BPDIAS','POPCT','PAINSCALE','ALZHD','ASTHMA','CAD','CANCER', \\\n",
    "                                'CEBVD','CHF','CKD','COPD','DEPRN','DIABTYP0','DIABTYP1','DIABTYP2','EDHIV', \\\n",
    "                                'ESRD','ETOHAB','HPE','HTN','HYPLIPID','OBESITY','OSA','OSTPRSIS','SUBSTAB', \\\n",
    "                                'NOCHRON','TOTCHRON','INJURY','INJURY72','RFV1_admit_rate'], \n",
    "                         outputCol=\"features\")  \n",
    "   \n",
    "NHAMCS = va.setHandleInvalid(\"skip\").transform(NHAMCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing set\n",
    "training, testing = NHAMCS.randomSplit([0.8, 0.2], seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle class imbalance\n",
    "\n",
    "# calculate balance ratio\n",
    "balRatio = training.select(\"ADM_OUTCOME\").where('ADM_OUTCOME == 0').count() / training.count()\n",
    "\n",
    "# add weights\n",
    "training = training.withColumn(\"classWeights\", when(training.ADM_OUTCOME == 1,balRatio).otherwise(1-balRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for logistic regression\n",
    "def lr_nhamcs (training_set, testing_set, reg_param=0, method=\"Standard\"):\n",
    "    if method==\"Standard\":\n",
    "        lr = LogisticRegression(featuresCol=\"features\", labelCol=\"ADM_OUTCOME\", weightCol=\"classWeights\", \\\n",
    "                                  maxIter=10, regParam=0, elasticNetParam=0)   \n",
    "    elif method==\"Ridge\":\n",
    "        lr = LogisticRegression(featuresCol=\"features\", labelCol=\"ADM_OUTCOME\", weightCol=\"classWeights\", \\\n",
    "                                  maxIter=10, regParam=reg_param, elasticNetParam=0)   \n",
    "    elif method==\"Lasso\":\n",
    "        lr = LogisticRegression(featuresCol=\"features\", labelCol=\"ADM_OUTCOME\", weightCol=\"classWeights\", \\\n",
    "                                  maxIter=10, regParam=reg_param, elasticNetParam=1)   \n",
    "        \n",
    "    # Fit the model\n",
    "    admModel = lr.fit(training_set)\n",
    "\n",
    "    # predict on testing set \n",
    "    predict_test=admModel.transform(testing_set)\n",
    "    \n",
    "    # make evaluator \n",
    "    evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"ADM_OUTCOME\")\n",
    "    \n",
    "    return evaluator.evaluate(predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC for standard LR is:  0.7878118746993313\n"
     ]
    }
   ],
   "source": [
    "# test standard LR model\n",
    "print(\"ROC-AUC for standard LR is: \", lr_nhamcs(training,testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC for Ridge LR with reg_param= 0.0  is:  0.7878118746993296\n",
      "ROC-AUC for Ridge LR with reg_param= 0.1  is:  0.7878120991146862\n",
      "ROC-AUC for Ridge LR with reg_param= 0.2  is:  0.7878155027476266\n",
      "ROC-AUC for Ridge LR with reg_param= 0.3  is:  0.7878225718314305\n",
      "ROC-AUC for Ridge LR with reg_param= 0.4  is:  0.7878323338995342\n",
      "ROC-AUC for Ridge LR with reg_param= 0.5  is:  0.7878399640217282\n",
      "ROC-AUC for Ridge LR with reg_param= 0.6  is:  0.7878427318111566\n",
      "ROC-AUC for Ridge LR with reg_param= 0.7  is:  0.7878414975266823\n",
      "ROC-AUC for Ridge LR with reg_param= 0.8  is:  0.7878381686988603\n",
      "ROC-AUC for Ridge LR with reg_param= 0.9  is:  0.7878372336348662\n",
      "ROC-AUC for Ridge LR with reg_param= 1.0  is:  0.7878359993503897\n"
     ]
    }
   ],
   "source": [
    "# test Ridge LR model for different values of the regularizatoin parameter\n",
    "for i in np.arange(0.0, 1.1, 0.1):\n",
    "    i = np.round(i,1)\n",
    "    print(\"ROC-AUC for Ridge LR with reg_param=\", i, \\\n",
    "          \" is: \", lr_nhamcs(training,testing, i,\"Ridge\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC for Lasso LR with reg_param= 0.0  is:  0.787811874699332\n",
      "ROC-AUC for Lasso LR with reg_param= 0.1  is:  0.8122173441803751\n",
      "ROC-AUC for Lasso LR with reg_param= 0.2  is:  0.7748009454469451\n",
      "ROC-AUC for Lasso LR with reg_param= 0.3  is:  0.5\n",
      "ROC-AUC for Lasso LR with reg_param= 0.4  is:  0.5\n",
      "ROC-AUC for Lasso LR with reg_param= 0.5  is:  0.5\n",
      "ROC-AUC for Lasso LR with reg_param= 0.6  is:  0.5\n",
      "ROC-AUC for Lasso LR with reg_param= 0.7  is:  0.5\n",
      "ROC-AUC for Lasso LR with reg_param= 0.8  is:  0.5\n",
      "ROC-AUC for Lasso LR with reg_param= 0.9  is:  0.5\n",
      "ROC-AUC for Lasso LR with reg_param= 1.0  is:  0.5\n"
     ]
    }
   ],
   "source": [
    "# test Lasso LR model for different values of the regularizatoin parameter\n",
    "for i in np.arange(0.0, 1.1, 0.1):\n",
    "    i = np.round(i,1)\n",
    "    print(\"ROC-AUC for Lasso LR with reg_param=\", i, \\\n",
    "          \" is: \", lr_nhamcs(training,testing, i,\"Lasso\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model with best hyperparameters (Ridge, regParam=1.0)\n",
    "#lr = LogisticRegression(featuresCol=\"features\", labelCol=\"ADM_OUTCOME\", weightCol=\"classWeights\", \\\n",
    "#                        maxIter=10, regParam=1.0, elasticNetParam=0) \n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"ADM_OUTCOME\", weightCol=\"classWeights\", \\\n",
    "                                  maxIter=10, regParam=0.1, elasticNetParam=1)   \n",
    "\n",
    "admModel = lr.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "admModel.write().overwrite().save(\"../models/001-log_regress-no_RFV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28K\t../models/001-log_regress-no_RFV/data\n",
      "20K\t../models/001-log_regress-no_RFV/metadata\n",
      "52K\t../models/001-log_regress-no_RFV\n"
     ]
    }
   ],
   "source": [
    "# get size on disk\n",
    "!du -h ../models/001-log_regress-no_RFV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on testing set \n",
    "predict_test=admModel.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.812217344180374\n"
     ]
    }
   ],
   "source": [
    "# calculate AUC \n",
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"ADM_OUTCOME\")\n",
    "print(\"ROC-AUC:\", evaluator.evaluate(predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.37724191885729574\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "print(\"F1 score:\",evaluator.setMetricName(\"areaUnderPR\").evaluate(predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7753217166430638\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "correct = predict_test.where('prediction == ADM_OUTCOME').count()\n",
    "total = predict_test.count()\n",
    "\n",
    "print(\"Accuracy:\", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "tn: 11325  fn: 592\n",
      "fp: 3057   tp: 1267\n"
     ]
    }
   ],
   "source": [
    "# compute confusion matrix\n",
    "tp = predict_test.where('prediction == 1 and ADM_OUTCOME==1').count() \n",
    "fp = predict_test.where('prediction == 1 and ADM_OUTCOME==0').count() \n",
    "tn = predict_test.where('prediction == 0 and ADM_OUTCOME==0').count() \n",
    "fn = predict_test.where('prediction == 0 and ADM_OUTCOME==1').count() \n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print('tn:',tn,' fn:',fn)\n",
    "print('fp:',fp, '  tp:',tp,)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Name: pyspark\n",
      "Version: 2.4.5\n",
      "Summary: Apache Spark Python API\n",
      "Home-page: https://github.com/apache/spark/tree/master/python\n",
      "Author: Spark Developers\n",
      "Author-email: dev@spark.apache.org\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: /usr/local/spark-2.4.5-bin-hadoop2.7/python\n",
      "Requires: py4j\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
