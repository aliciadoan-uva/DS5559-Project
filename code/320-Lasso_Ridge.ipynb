{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Admission Prediction from NHAMCS\n",
    "## Initial LR model\n",
    "### DS5559: Big Data Analysis\n",
    "### Thomas Hartka, Alicia Doan, Michael Langmayr\n",
    "Created: 7/28/2020 \n",
    "  \n",
    "In this notebook creates and analyzes our lasso and ridge regression models.  The regularization parameters are found using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preferences\n",
    "weight_outcome = True        # use weights to handle class imbalance\n",
    "scaling = True               # scale data\n",
    "\n",
    "# variables to include\n",
    "pred_totchron = True         # total chronic disease\n",
    "pred_resid = True            # place of residence\n",
    "pred_comorbid = True         # place of residence\n",
    "pred_RFV = True              # historical admit rate based on RFV\n",
    "pred_vitals = True           # vital signs (heart reate, blood pressure, etc.)\n",
    "pred_arrival = True          # arrival time and year\n",
    "pred_injury = True           # visits associated with injuries \n",
    "\n",
    "# ridge and lasso regression settings\n",
    "max_iter = 100               # maximum iterations\n",
    "elasticNet = 1                 # 0=Ridge, 1=Lasso\n",
    "\n",
    "# seed for random split\n",
    "SEED = 314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data directory\n",
    "data_dir = \"../data\"\n",
    "results_dir = \"../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.feature import *  \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHAMCS = spark.read.parquet(data_dir + \"/NHAMCS_processed_bc.2014-2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to include\n",
    "predictors = ['AGEYEAR','SEXMALE']                    # all models have age and sex\n",
    "\n",
    "if pred_totchron: predictors += ['TOTCHRON']          # total chronic conditions\n",
    "\n",
    "if pred_comorbid: predictors += ['ALZHD','ASTHMA',    # preexisting health conditions\n",
    "        'CAD','CANCER', 'CEBVD','CHF','CKD','COPD',\n",
    "        'DEPRN','DIABTYP0','DIABTYP1','DIABTYP2',\n",
    "        'EDHIV','ESRD','ETOHAB','HPE','HTN',\n",
    "        'HYPLIPID','OBESITY','OSA','OSTPRSIS',\n",
    "        'SUBSTAB','NOCHRON']\n",
    "\n",
    "if pred_vitals: predictors += ['PULSE','TEMPF',        # vital signs\n",
    "        'RESPR','BPSYS','BPDIAS','POPCT','PAINSCALE']\n",
    "    \n",
    "if pred_RFV: predictors += ['RFV1_admit_rate']         # historical admission rate based on RFV\n",
    "    \n",
    "if pred_arrival: predictors += ['ARRTIMEMIN','YEAR']   # arrival time and year\n",
    "\n",
    "if pred_injury: predictors += ['INJURY','INJURY72']    # visits associated with injuries \n",
    "    \n",
    "if pred_resid: predictors += ['RESONE']                # residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for crossvalidation for some reason we need to call the output 'label'\n",
    "NHAMCS = NHAMCS.withColumnRenamed(\"ADM_OUTCOME\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and calculate class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing set\n",
    "training, testing = NHAMCS.randomSplit([0.8, 0.2], SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle class imbalance\n",
    "\n",
    "# calculate balance ratio\n",
    "balRatio = training.select(\"label\").where('label == 0').count() / training.count()\n",
    "\n",
    "# add weights\n",
    "training = training.withColumn(\"classWeights\", when(training.label == 1,balRatio).otherwise(1-balRatio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaledFeatures\n",
      "Using outcome weights\n"
     ]
    }
   ],
   "source": [
    "# perform string indexing to prepare for OHE for residence variable\n",
    "rsi = StringIndexer(inputCol=\"RESIDNCE\", outputCol=\"RESINDEX\")\n",
    "\n",
    "# perform OHE on residence variable\n",
    "rohe = OneHotEncoder(inputCol='RESINDEX', outputCol='RESONE')\n",
    "\n",
    "# assemble vector\n",
    "va = VectorAssembler(inputCols=predictors, outputCol=\"features\", handleInvalid='skip')  \n",
    "\n",
    "# scaler for data\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "# select whether to use scaled features\n",
    "if scaling == True:\n",
    "    featureCol = 'scaledFeatures'\n",
    "else:\n",
    "    featureCol = 'features'\n",
    "    \n",
    "print(featureCol)\n",
    "\n",
    "# set up model\n",
    "if weight_outcome:\n",
    "    print(\"Using outcome weights\")\n",
    "    lr = LogisticRegression(featuresCol=featureCol, labelCol=\"label\", weightCol=\"classWeights\", \\\n",
    "                              maxIter=max_iter, elasticNetParam=elasticNet)\n",
    "else:\n",
    "    lr = LogisticRegression(featuresCol=featureCol, labelCol=\"label\", \\\n",
    "                               maxIter=max_iter, elasticNetParam=elasticNet)\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = Pipeline(stages=[rsi, rohe, va, scaler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up parameters for cross validation\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.00001,0.00005,0.0001,0.0005,0.001,0.005,0.01,1.0,10]) \\\n",
    "    .build()\n",
    "\n",
    "# set up  for cross validator\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=5,\n",
    "                          seed = SEED)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.22 s, sys: 684 ms, total: 3.9 s\n",
      "Wall time: 10min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the pipeline)\n",
    "cvModel = crossval.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8237444883658015,\n",
       " 0.8240205191720915,\n",
       " 0.8241668926829173,\n",
       " 0.8237079296116474,\n",
       " 0.8237803176866568,\n",
       " 0.8231086145236612,\n",
       " 0.8202309981106647,\n",
       " 0.5,\n",
       " 0.5]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract LR model from cross validator\n",
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrBest = cvModel.bestModel.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  -0.0\n",
      "AGEYEAR : 0.4151\n",
      "SEXMALE : 0.0747\n",
      "TOTCHRON : 0.0264\n",
      "ALZHD : 0.0129\n",
      "ASTHMA : -0.0745\n",
      "CAD : 0.0832\n",
      "CANCER : 0.1045\n",
      "CEBVD : 0.0873\n",
      "CHF : 0.0674\n",
      "CKD : 0.0892\n",
      "COPD : 0.0096\n",
      "DEPRN : 0.0603\n",
      "DIABTYP0 : 0.0036\n",
      "DIABTYP1 : 0.0548\n",
      "DIABTYP2 : 0.0267\n",
      "EDHIV : -0.006\n",
      "ESRD : 0.0175\n",
      "ETOHAB : 0.0506\n",
      "HPE : 0.0281\n",
      "HTN : 0.0264\n",
      "HYPLIPID : 0.0412\n",
      "OBESITY : 0.0937\n",
      "OSA : 0.004\n",
      "OSTPRSIS : 0.0281\n",
      "SUBSTAB : 0.0053\n",
      "NOCHRON : -0.2099\n",
      "PULSE : 0.2048\n",
      "TEMPF : -0.0365\n",
      "RESPR : 0.113\n",
      "BPSYS : -0.0875\n",
      "BPDIAS : -0.005\n",
      "POPCT : -0.1125\n",
      "PAINSCALE : 0.058\n",
      "RFV1_admit_rate : 0.7581\n",
      "ARRTIMEMIN : -0.0124\n",
      "YEAR : -0.0011\n",
      "INJURY : -0.0071\n",
      "INJURY72 : -0.0164\n",
      "RESONE : -0.0423\n",
      "       : 0.017\n",
      "       : 0.0057\n",
      "       : 0.0389\n",
      "       : 0.029\n",
      "       : -0.0173\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"Intercept: \", np.round(lrBest.intercept,4))\n",
    "for i,coeff in enumerate(lrBest.coefficients):\n",
    "    if(i<len(predictors)):\n",
    "        print(predictors[i], \":\", np.round(coeff,4))\n",
    "    else:\n",
    "        print(\"       :\", np.round(coeff,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a predictions\n",
    "pred_train = cvModel.transform(training)\n",
    "pred_test = cvModel.transform(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "tn: 11226  fn: 520\n",
      "fp: 3156   tp: 1339\n",
      "\n",
      "Predicted positive: 4495\n",
      "Predicted negitive: 11746\n",
      "\n",
      "Accuracy 0.7736592574348871\n",
      "\n",
      "Precision: 0.2978865406006674\n",
      "Recall: 0.7202797202797203\n",
      "F1 score: 0.4214667925716084\n",
      "\n",
      "Sensitivity: 0.7202797202797203\n",
      "Specificity: 0.9557296100800272\n",
      "\n",
      "The area under ROC for train set is 0.8254751056932993\n",
      "The area under ROC for test set is 0.8258390198315085\n"
     ]
    }
   ],
   "source": [
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\")\n",
    "\n",
    "# compute confusion matrix\n",
    "tp = pred_test.where('prediction == 1 and label==1').count() \n",
    "fp = pred_test.where('prediction == 1 and label==0').count() \n",
    "tn = pred_test.where('prediction == 0 and label==0').count() \n",
    "fn = pred_test.where('prediction == 0 and label==1').count() \n",
    "\n",
    "acc = (tp+tn)/(tp+fp+tn+fn)\n",
    "prec = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "spec = tn / (tn + fn)\n",
    "f1 = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print('tn:',tn,' fn:',fn)\n",
    "print('fp:',fp, '  tp:',tp,)  \n",
    "\n",
    "print('\\nPredicted positive:', tp+fp)\n",
    "print('Predicted negitive:', tn+fn)\n",
    "\n",
    "print('\\nAccuracy', acc)\n",
    "\n",
    "print(\"\\nPrecision:\", prec)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "print(\"\\nSensitivity:\", recall)\n",
    "print(\"Specificity:\", spec)\n",
    "\n",
    "print(\"\\nThe area under ROC for train set is\", evaluator.setMetricName(\"areaUnderROC\").evaluate(pred_train))\n",
    "print(\"The area under ROC for test set is\", evaluator.evaluate(pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
