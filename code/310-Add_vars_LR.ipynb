{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Admission Prediction from NHAMCS\n",
    "## Initial LR model\n",
    "### DS5559: Big Data Analysis\n",
    "### Thomas Hartka, Alicia Doan, Michael Langmayr\n",
    "Created: 7/15/2020 \n",
    "  \n",
    "In this notebook creates and analyzes our logistic regression model using all varaiblespredicting hospital admission in the NHAMCS database.  Weight of the outcomes is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preferences\n",
    "weight_outcome = True    # use weights to handle class imbalance\n",
    "\n",
    "# variables to include\n",
    "pred_totchron = True     # total chronic disease\n",
    "pred_resid = True        # place of residence\n",
    "pred_comorbid = True     # place of residence\n",
    "pred_RFV = True          # historical admit rate based on RFV\n",
    "pred_vitals = True       # vital signs (heart reate, blood pressure, etc.)\n",
    "pred_arrival = True      # arrival time and year\n",
    "pred_injury = True       # visits associated with injuries \n",
    "\n",
    "# logistic regression settings\n",
    "max_iter = 100           # maximum iterations\n",
    "\n",
    "# seed for random split\n",
    "SEED = 314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data directory\n",
    "data_dir = \"../data\"\n",
    "results_dir = \"../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.feature import *  \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHAMCS = spark.read.parquet(data_dir + \"/NHAMCS_processed_bc.2014-2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to include\n",
    "predictors = ['AGEYEAR','SEXMALE']                    # all models have age and sex\n",
    "\n",
    "if pred_totchron: predictors += ['TOTCHRON']          # total chronic conditions\n",
    "\n",
    "if pred_comorbid: predictors += ['ALZHD','ASTHMA',    # preexisting health conditions\n",
    "        'CAD','CANCER', 'CEBVD','CHF','CKD','COPD',\n",
    "        'DEPRN','DIABTYP0','DIABTYP1','DIABTYP2',\n",
    "        'EDHIV','ESRD','ETOHAB','HPE','HTN',\n",
    "        'HYPLIPID','OBESITY','OSA','OSTPRSIS',\n",
    "        'SUBSTAB','NOCHRON']\n",
    "\n",
    "if pred_vitals: predictors += ['PULSE','TEMPF',        # vital signs\n",
    "        'RESPR','BPSYS','BPDIAS','POPCT','PAINSCALE']\n",
    "    \n",
    "if pred_RFV: predictors += ['RFV1_admit_rate']         # historical admission rate based on RFV\n",
    "    \n",
    "if pred_arrival: predictors += ['ARRTIMEMIN','YEAR']   # arrival time and year\n",
    "\n",
    "if pred_injury: predictors += ['INJURY','INJURY72']    # visits associated with injuries \n",
    "    \n",
    "if pred_resid: predictors += ['RESONE']                # residence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and calculate class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing set\n",
    "training, testing = NHAMCS.randomSplit([0.8, 0.2], SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle class imbalance\n",
    "\n",
    "# calculate balance ratio\n",
    "balRatio = training.select(\"ADM_OUTCOME\").where('ADM_OUTCOME == 0').count() / training.count()\n",
    "\n",
    "# add weights\n",
    "training = training.withColumn(\"classWeights\", when(training.ADM_OUTCOME == 1,balRatio).otherwise(1-balRatio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform string indexing to prepare for OHE for residence variable\n",
    "rsi = StringIndexer(inputCol=\"RESIDNCE\", outputCol=\"RESINDEX\")\n",
    "\n",
    "# perform OHE on residence variable\n",
    "rohe = OneHotEncoder(inputCol='RESINDEX', outputCol='RESONE')\n",
    "\n",
    "# assemble vector\n",
    "va = VectorAssembler(inputCols=predictors, outputCol=\"features\", handleInvalid='skip')  \n",
    "\n",
    "# logistic regression model (no lasso or ridge)\n",
    "# set up LR model\n",
    "if weight_outcome:\n",
    "    lr = LogisticRegression(featuresCol=\"features\", labelCol=\"ADM_OUTCOME\", weightCol=\"classWeights\", \\\n",
    "                              maxIter=max_iter, regParam=0, elasticNetParam=0)\n",
    "else:\n",
    "    lr = LogisticRegression(featuresCol=\"features\", labelCol=\"ADM_OUTCOME\", \\\n",
    "                               maxIter=max_iter, regParam=0, elasticNetParam=0)\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = Pipeline(stages=[rsi, rohe, va, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.6 ms, sys: 5.08 ms, total: 33.7 ms\n",
      "Wall time: 34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the pipeline\n",
    "model = pipeline.fit(training)\n",
    "\n",
    "# extract LR model from pipeline\n",
    "lrTrain = model.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  -0.0\n",
      "AGEYEAR : 0.016\n",
      "SEXMALE : 0.145\n",
      "TOTCHRON : 0.0609\n",
      "ALZHD : 0.101\n",
      "ASTHMA : -0.2731\n",
      "CAD : 0.3404\n",
      "CANCER : 0.5721\n",
      "CEBVD : 0.4557\n",
      "CHF : 0.3666\n",
      "CKD : 0.5555\n",
      "COPD : -0.0143\n",
      "DEPRN : 0.1651\n",
      "DIABTYP0 : -0.0403\n",
      "DIABTYP1 : 0.5805\n",
      "DIABTYP2 : 0.0983\n",
      "EDHIV : -0.0754\n",
      "ESRD : 0.162\n",
      "ETOHAB : 0.2441\n",
      "HPE : 0.2341\n",
      "HTN : 0.0253\n",
      "HYPLIPID : 0.0979\n",
      "OBESITY : 0.458\n",
      "OSA : 0.0273\n",
      "OSTPRSIS : 0.3127\n",
      "SUBSTAB : -0.0147\n",
      "NOCHRON : -0.4222\n",
      "PULSE : 0.0073\n",
      "TEMPF : -0.0042\n",
      "RESPR : 0.0162\n",
      "BPSYS : 0.0001\n",
      "BPDIAS : -0.002\n",
      "POPCT : -0.0047\n",
      "PAINSCALE : 0.0148\n",
      "RFV1_admit_rate : 5.638\n",
      "ARRTIMEMIN : -0.0\n",
      "YEAR : -0.0009\n",
      "INJURY : -0.0276\n",
      "INJURY72 : -0.0478\n",
      "RESONE : -0.1898\n",
      "       : 0.1495\n",
      "       : 0.0528\n",
      "       : 0.4575\n",
      "       : 0.3692\n",
      "       : -0.2022\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"Intercept: \", np.round(lrTrain.intercept,4))\n",
    "for i,coeff in enumerate(lrTrain.coefficients):\n",
    "    if(i<len(predictors)):\n",
    "        print(predictors[i], \":\", np.round(coeff,4))\n",
    "    else:\n",
    "        print(\"       :\", np.round(coeff,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lrTrain.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a predictions\n",
    "pred_train = model.transform(training)\n",
    "pred_test = model.transform(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "tn: 11169  fn: 514\n",
      "fp: 3213   tp: 1345\n",
      "\n",
      "Predicted positive: 4558\n",
      "Predicted negitive: 11683\n",
      "\n",
      "Accuracy 0.7705190567083308\n",
      "\n",
      "Precision: 0.29508556384379114\n",
      "Recall: 0.7235072619688004\n",
      "F1 score: 0.41919900264921306\n",
      "\n",
      "Sensitivity: 0.7235072619688004\n",
      "Specificity: 0.9560044509115809\n",
      "\n",
      "The area under ROC for train set is 0.8258379243671996\n",
      "The area under ROC for test set is 0.825720453716986\n"
     ]
    }
   ],
   "source": [
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"ADM_OUTCOME\")\n",
    "\n",
    "# compute confusion matrix\n",
    "tp = pred_test.where('prediction == 1 and ADM_OUTCOME==1').count() \n",
    "fp = pred_test.where('prediction == 1 and ADM_OUTCOME==0').count() \n",
    "tn = pred_test.where('prediction == 0 and ADM_OUTCOME==0').count() \n",
    "fn = pred_test.where('prediction == 0 and ADM_OUTCOME==1').count() \n",
    "\n",
    "acc = (tp+tn)/(tp+fp+tn+fn)\n",
    "prec = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "spec = tn / (tn + fn)\n",
    "f1 = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print('tn:',tn,' fn:',fn)\n",
    "print('fp:',fp, '  tp:',tp,)  \n",
    "\n",
    "print('\\nPredicted positive:', tp+fp)\n",
    "print('Predicted negitive:', tn+fn)\n",
    "\n",
    "print('\\nAccuracy', acc)\n",
    "\n",
    "print(\"\\nPrecision:\", prec)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "print(\"\\nSensitivity:\", recall)\n",
    "print(\"Specificity:\", spec)\n",
    "\n",
    "print(\"\\nThe area under ROC for train set is\", evaluator.setMetricName(\"areaUnderROC\").evaluate(pred_train))\n",
    "print(\"The area under ROC for test set is\", evaluator.evaluate(pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
