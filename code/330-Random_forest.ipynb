{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Admission Prediction from NHAMCS\n",
    "## Initial LR model\n",
    "### DS5559: Big Data Analysis\n",
    "### Thomas Hartka, Alicia Doan, Michael Langmayr\n",
    "Created: 7/28/2020 \n",
    "  \n",
    "In this notebook creates and analyzes our lasso and ridge regression models.  The regularization parameters are found using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preferences\n",
    "down_sample = True             # use downsampling to handle class imbalance\n",
    "scaling = False              # scale data\n",
    "\n",
    "# variables to include\n",
    "pred_totchron = True         # total chronic disease\n",
    "pred_resid = True            # place of residence\n",
    "pred_comorbid = True         # place of residence\n",
    "pred_RFV = True              # historical admit rate based on RFV\n",
    "pred_vitals = True           # vital signs (heart reate, blood pressure, etc.)\n",
    "pred_arrival = True          # arrival time and year\n",
    "pred_injury = True           # visits associated with injuries \n",
    "\n",
    "# seed for random split\n",
    "SEED = 314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data directory\n",
    "data_dir = \"../data\"\n",
    "results_dir = \"../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.feature import *  \n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHAMCS = spark.read.parquet(data_dir + \"/NHAMCS_processed_bc.2014-2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to include\n",
    "predictors = ['AGEYEAR','SEXMALE']                    # all models have age and sex\n",
    "\n",
    "if pred_totchron: predictors += ['TOTCHRON']          # total chronic conditions\n",
    "\n",
    "if pred_comorbid: predictors += ['ALZHD','ASTHMA',    # preexisting health conditions\n",
    "        'CAD','CANCER', 'CEBVD','CHF','CKD','COPD',\n",
    "        'DEPRN','DIABTYP0','DIABTYP1','DIABTYP2',\n",
    "        'EDHIV','ESRD','ETOHAB','HPE','HTN',\n",
    "        'HYPLIPID','OBESITY','OSA','OSTPRSIS',\n",
    "        'SUBSTAB','NOCHRON']\n",
    "\n",
    "if pred_vitals: predictors += ['PULSE','TEMPF',        # vital signs\n",
    "        'RESPR','BPSYS','BPDIAS','POPCT','PAINSCALE']\n",
    "    \n",
    "if pred_RFV: predictors += ['RFV1_admit_rate']         # historical admission rate based on RFV\n",
    "    \n",
    "if pred_arrival: predictors += ['ARRTIMEMIN','YEAR']   # arrival time and year\n",
    "\n",
    "if pred_injury: predictors += ['INJURY','INJURY72']    # visits associated with injuries \n",
    "    \n",
    "if pred_resid: predictors += ['RESONE']                # residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for crossvalidation for some reason we need to call the output 'label'\n",
    "NHAMCS = NHAMCS.withColumnRenamed(\"ADM_OUTCOME\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df, target, positive_label, negative_label):\n",
    "    \"\"\"\n",
    "    df              spark dataframe\n",
    "    target          str, target variable\n",
    "    positive_label  int, value of positive label\n",
    "    negative_label  int, value of negative label\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    positives = df.filter(df[target] == positive_label)\n",
    "    num_positives = positives.count()\n",
    "    negatives =  df.filter(df[target] == negative_label)\n",
    "    num_negatives = negatives.count()\n",
    "    \n",
    "    if (num_positives > num_negatives): # downsample positives\n",
    "        sampled_df = positives.sample(withReplacement=False, fraction=num_negatives/num_positives, seed=SEED)\n",
    "        df_b = sampled_df.union(negatives)\n",
    "    elif (num_negatives > num_positives): # downsample negatives\n",
    "        sampled_df = negatives.sample(withReplacement=False, fraction=num_positives/num_negatives, seed=SEED)\n",
    "        df_b = sampled_df.union(positives)\n",
    "\n",
    "    return df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81081"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NHAMCS.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and calculate class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing set\n",
    "training, testing = NHAMCS.randomSplit([0.8, 0.2], SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling\n"
     ]
    }
   ],
   "source": [
    "if down_sample == True:\n",
    "    print(\"Downsampling\")\n",
    "    training = downsample(training,'label', 1, 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform string indexing to prepare for OHE for residence variable\n",
    "rsi = StringIndexer(inputCol=\"RESIDNCE\", outputCol=\"RESINDEX\")\n",
    "\n",
    "# perform OHE on residence variable\n",
    "rohe = OneHotEncoder(inputCol='RESINDEX', outputCol='RESONE')\n",
    "\n",
    "# assemble vector\n",
    "va = VectorAssembler(inputCols=predictors, outputCol=\"features\", handleInvalid='skip')  \n",
    "\n",
    "# scaler for data\n",
    "scaler = MaxAbsScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "# select whether to use scaled features\n",
    "if scaling == True:\n",
    "    featureCol = 'scaledFeatures'\n",
    "else:\n",
    "    featureCol = 'features'\n",
    "    \n",
    "# set up model\n",
    "rf = RandomForestClassifier(labelCol='label',featuresCol='scaledFeatures', numTrees=100)\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = Pipeline(stages=[rsi, rohe, va, scaler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up parameters for cross validation\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [50,100,150,200]) \\\n",
    "    .addGrid(rf.maxDepth, [5,10]) \\\n",
    "    .build()\n",
    "\n",
    "# set up  for cross validator\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=5,\n",
    "                          seed = SEED)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.92 s, sys: 617 ms, total: 3.53 s\n",
      "Wall time: 16min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the pipeline\n",
    "cvModel = crossval.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8078129762700031,\n",
       " 0.8256433796107218,\n",
       " 0.8085120109955183,\n",
       " 0.8269801904482001,\n",
       " 0.808154573590713,\n",
       " 0.82700789190938,\n",
       " 0.8098880954990817,\n",
       " 0.8274814915739511]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract LR model from cross validator\n",
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrBest = cvModel.bestModel.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a predictions\n",
    "pred_train = cvModel.transform(training)\n",
    "pred_test = cvModel.transform(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "tn: 10939  fn: 474\n",
      "fp: 3443   tp: 1385\n",
      "\n",
      "Predicted positive: 4828\n",
      "Predicted negitive: 11413\n",
      "\n",
      "Accuracy 0.7588202696878271\n",
      "\n",
      "Precision: 0.2868682684341342\n",
      "Recall: 0.7450242065626681\n",
      "F1 score: 0.4142365784357709\n",
      "\n",
      "Sensitivity: 0.7450242065626681\n",
      "Specificity: 0.9584684132130027\n",
      "\n",
      "The area under ROC for train set is 0.8848930696689579\n",
      "The area under ROC for test set is 0.8341749657336401\n"
     ]
    }
   ],
   "source": [
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\")\n",
    "\n",
    "# compute confusion matrix\n",
    "tp = pred_test.where('prediction == 1 and label==1').count() \n",
    "fp = pred_test.where('prediction == 1 and label==0').count() \n",
    "tn = pred_test.where('prediction == 0 and label==0').count() \n",
    "fn = pred_test.where('prediction == 0 and label==1').count() \n",
    "\n",
    "acc = (tp+tn)/(tp+fp+tn+fn)\n",
    "prec = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "spec = tn / (tn + fn)\n",
    "f1 = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print('tn:',tn,' fn:',fn)\n",
    "print('fp:',fp, '  tp:',tp,)  \n",
    "\n",
    "print('\\nPredicted positive:', tp+fp)\n",
    "print('Predicted negitive:', tn+fn)\n",
    "\n",
    "print('\\nAccuracy', acc)\n",
    "\n",
    "print(\"\\nPrecision:\", prec)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "print(\"\\nSensitivity:\", recall)\n",
    "print(\"Specificity:\", spec)\n",
    "\n",
    "print(\"\\nThe area under ROC for train set is\", evaluator.setMetricName(\"areaUnderROC\").evaluate(pred_train))\n",
    "print(\"The area under ROC for test set is\", evaluator.evaluate(pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
