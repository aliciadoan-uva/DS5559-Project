{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Admission Prediction from NHAMCS\n",
    "## Initial LR model\n",
    "### DS5559: Big Data Analysis\n",
    "### Thomas Hartka, Alicia Doan, Michael Langmayr\n",
    "Created: 7/28/2020 \n",
    "  \n",
    "In this notebook creates and analyzes a linear support vector machine model.  The regularization parameters are found using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preferences\n",
    "weight_outcome = True        # use weights to handle class imbalance\n",
    "scaling = True               # scale data\n",
    "data_reduction = 1           # fraction of data to use (set to 1.0 for all data)\n",
    "\n",
    "# variables to include\n",
    "pred_totchron = True         # total chronic disease\n",
    "pred_resid = True            # place of residence\n",
    "pred_comorbid = True         # place of residence\n",
    "pred_RFV = True              # historical admit rate based on RFV\n",
    "pred_vitals = True           # vital signs (heart reate, blood pressure, etc.)\n",
    "pred_arrival = True          # arrival time and year\n",
    "pred_injury = True           # visits associated with injuries \n",
    "\n",
    "# ridge and lasso regression settings\n",
    "max_iter = 100               # maximum iterations\n",
    "\n",
    "# seed for random split\n",
    "SEED = 314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data directory\n",
    "data_dir = \"../data\"\n",
    "results_dir = \"../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.feature import *  \n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHAMCS = spark.read.parquet(data_dir + \"/NHAMCS_processed_bc.2014-2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce data if needed\n",
    "Due to the time needed to run these models, tuning might be performed using a reduced data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_reduction < 1:\n",
    "    NHAMCS = NHAMCS.sample(withReplacement=False, fraction=data_reduction, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81081"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NHAMCS.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to include\n",
    "predictors = ['AGEYEAR','SEXMALE']                    # all models have age and sex\n",
    "\n",
    "if pred_totchron: predictors += ['TOTCHRON']          # total chronic conditions\n",
    "\n",
    "if pred_comorbid: predictors += ['ALZHD','ASTHMA',    # preexisting health conditions\n",
    "        'CAD','CANCER', 'CEBVD','CHF','CKD','COPD',\n",
    "        'DEPRN','DIABTYP0','DIABTYP1','DIABTYP2',\n",
    "        'EDHIV','ESRD','ETOHAB','HPE','HTN',\n",
    "        'HYPLIPID','OBESITY','OSA','OSTPRSIS',\n",
    "        'SUBSTAB','NOCHRON']\n",
    "\n",
    "if pred_vitals: predictors += ['PULSE','TEMPF',        # vital signs\n",
    "        'RESPR','BPSYS','BPDIAS','POPCT','PAINSCALE']\n",
    "    \n",
    "if pred_RFV: predictors += ['RFV1_admit_rate']         # historical admission rate based on RFV\n",
    "    \n",
    "if pred_arrival: predictors += ['ARRTIMEMIN','YEAR']   # arrival time and year\n",
    "\n",
    "if pred_injury: predictors += ['INJURY','INJURY72']    # visits associated with injuries \n",
    "    \n",
    "if pred_resid: predictors += ['RESONE']                # residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for crossvalidation for some reason we need to call the output 'label'\n",
    "NHAMCS = NHAMCS.withColumnRenamed(\"ADM_OUTCOME\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and calculate class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing set\n",
    "training, testing = NHAMCS.randomSplit([0.8, 0.2], SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle class imbalance\n",
    "\n",
    "# calculate balance ratio\n",
    "balRatio = training.select(\"label\").where('label == 0').count() / training.count()\n",
    "\n",
    "# add weights\n",
    "training = training.withColumn(\"classWeights\", when(training.label == 1,balRatio).otherwise(1-balRatio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaledFeatures\n",
      "Using outcome weights\n"
     ]
    }
   ],
   "source": [
    "# perform string indexing to prepare for OHE for residence variable\n",
    "rsi = StringIndexer(inputCol=\"RESIDNCE\", outputCol=\"RESINDEX\")\n",
    "\n",
    "# perform OHE on residence variable\n",
    "rohe = OneHotEncoder(inputCol='RESINDEX', outputCol='RESONE')\n",
    "\n",
    "# assemble vector\n",
    "va = VectorAssembler(inputCols=predictors, outputCol=\"features\", handleInvalid='skip')  \n",
    "\n",
    "# scaler for data\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "# select whether to use scaled features\n",
    "if scaling == True:\n",
    "    featureCol = 'scaledFeatures'\n",
    "else:\n",
    "    featureCol = 'features'\n",
    "    \n",
    "print(featureCol)\n",
    "\n",
    "# set up model\n",
    "if weight_outcome:\n",
    "    print(\"Using outcome weights\")\n",
    "    svc = LinearSVC(featuresCol=featureCol, labelCol=\"label\", weightCol=\"classWeights\", \\\n",
    "                              maxIter=max_iter, standardization=False)\n",
    "else:\n",
    "    svc = LinearSVC(featuresCol=featureCol, labelCol=\"label\", \\\n",
    "                               maxIter=max_iter, standardization=False)\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = Pipeline(stages=[rsi, rohe, va, scaler, svc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up parameters for cross validation\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(svc.regParam, [0,0.0001, 0.001, 0.01, 0.1]) \\\n",
    "    .build()\n",
    "\n",
    "# set up  for cross validator\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=5,\n",
    "                          seed = SEED)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.26 s, sys: 876 ms, total: 4.13 s\n",
      "Wall time: 47min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the pipeline)\n",
    "cvModel = crossval.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8232845115107741,\n",
       " 0.8126078444415568,\n",
       " 0.823140437009303,\n",
       " 0.8231145991998885,\n",
       " 0.8220104244865923]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract LR model from cross validator\n",
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrBest = cvModel.bestModel.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a predictions\n",
    "pred_train = cvModel.transform(training)\n",
    "pred_test = cvModel.transform(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "tn: 11300  fn: 542\n",
      "fp: 3082   tp: 1317\n",
      "\n",
      "Predicted positive: 4399\n",
      "Predicted negitive: 11842\n",
      "\n",
      "Accuracy 0.776861030724709\n",
      "\n",
      "Precision: 0.2993862241418504\n",
      "Recall: 0.708445400753093\n",
      "F1 score: 0.4209012464046021\n",
      "\n",
      "Sensitivity: 0.708445400753093\n",
      "Specificity: 0.9542307042729269\n",
      "\n",
      "The area under ROC for train set is 0.8250069761081206\n",
      "The area under ROC for test set is 0.8252571482089136\n"
     ]
    }
   ],
   "source": [
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\")\n",
    "\n",
    "# compute confusion matrix\n",
    "tp = pred_test.where('prediction == 1 and label==1').count() \n",
    "fp = pred_test.where('prediction == 1 and label==0').count() \n",
    "tn = pred_test.where('prediction == 0 and label==0').count() \n",
    "fn = pred_test.where('prediction == 0 and label==1').count() \n",
    "\n",
    "acc = (tp+tn)/(tp+fp+tn+fn)\n",
    "prec = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "spec = tn / (tn + fn)\n",
    "f1 = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print('tn:',tn,' fn:',fn)\n",
    "print('fp:',fp, '  tp:',tp,)  \n",
    "\n",
    "print('\\nPredicted positive:', tp+fp)\n",
    "print('Predicted negitive:', tn+fn)\n",
    "\n",
    "print('\\nAccuracy', acc)\n",
    "\n",
    "print(\"\\nPrecision:\", prec)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "print(\"\\nSensitivity:\", recall)\n",
    "print(\"Specificity:\", spec)\n",
    "\n",
    "print(\"\\nThe area under ROC for train set is\", evaluator.setMetricName(\"areaUnderROC\").evaluate(pred_train))\n",
    "print(\"The area under ROC for test set is\", evaluator.evaluate(pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
